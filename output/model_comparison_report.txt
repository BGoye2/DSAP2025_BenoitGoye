================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-27 21:44:17.423163
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.517

MAE (lower is better):
  Best: Gradient Boosting = 1.691

R² (higher is better):
  Best: Gradient Boosting = 0.910

MAPE (lower is better):
  Best: Gradient Boosting = 4.621

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9102
   Test RMSE: 2.5173
   Test MAE: 1.6913
   Overfit Gap: -1.7363

2. XGBoost
   Test R²: 0.9045
   Test RMSE: 2.5967
   Test MAE: 1.7220
   Overfit Gap: -1.7822

3. LightGBM
   Test R²: 0.8924
   Test RMSE: 2.7559
   Test MAE: 1.7983
   Overfit Gap: -1.5458

4. Random Forest
   Test R²: 0.8861
   Test RMSE: 2.8359
   Test MAE: 1.8310
   Overfit Gap: -1.4268

5. Decision Tree
   Test R²: 0.7883
   Test RMSE: 3.8650
   Test MAE: 2.5233
   Overfit Gap: -1.9584

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.9066
    MAE: 1.2484
    R²: 0.9437

  Test Performance:
    RMSE: 3.8650
    MAE: 2.5233
    MAPE: 6.82%
    R²: 0.7883
    Max Error: 19.2800
    Median Abs Error: 1.3941

  Cross-Validation:
    RMSE: 4.5309 ± nan
    R²: 0.6786 ± 0.0497

  Residual Analysis:
    Mean: 0.1142
    Std: 3.8634
    Skewness: 0.4083
    Kurtosis: 4.6417

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.4092
    MAE: 0.9001
    R²: 0.9692

  Test Performance:
    RMSE: 2.8359
    MAE: 1.8310
    MAPE: 4.90%
    R²: 0.8861
    Max Error: 14.5881
    Median Abs Error: 1.0950

  Cross-Validation:
    RMSE: 3.0790 ± nan
    R²: 0.8522 ± 0.0215

  Residual Analysis:
    Mean: 0.1741
    Std: 2.8306
    Skewness: 0.7174
    Kurtosis: 4.9163

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7810
    MAE: 0.6045
    R²: 0.9906

  Test Performance:
    RMSE: 2.5173
    MAE: 1.6913
    MAPE: 4.62%
    R²: 0.9102
    Max Error: 12.7708
    Median Abs Error: 1.1138

  Cross-Validation:
    RMSE: 2.9350 ± nan
    R²: 0.8650 ± 0.0287

  Residual Analysis:
    Mean: 0.1336
    Std: 2.5137
    Skewness: 0.3435
    Kurtosis: 4.5836

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8145
    MAE: 0.6142
    R²: 0.9897

  Test Performance:
    RMSE: 2.5967
    MAE: 1.7220
    MAPE: 4.70%
    R²: 0.9045
    Max Error: 12.8951
    Median Abs Error: 1.1283

  Cross-Validation:
    RMSE: 2.8892 ± nan
    R²: 0.8693 ± 0.0272

  Residual Analysis:
    Mean: 0.1109
    Std: 2.5943
    Skewness: 0.0813
    Kurtosis: 4.9838

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2100
    MAE: 0.8917
    R²: 0.9773

  Test Performance:
    RMSE: 2.7559
    MAE: 1.7983
    MAPE: 4.89%
    R²: 0.8924
    Max Error: 14.5688
    Median Abs Error: 1.1745

  Cross-Validation:
    RMSE: 3.0433 ± nan
    R²: 0.8546 ± 0.0307

  Residual Analysis:
    Mean: 0.1750
    Std: 2.7503
    Skewness: 0.3755
    Kurtosis: 5.7260

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial