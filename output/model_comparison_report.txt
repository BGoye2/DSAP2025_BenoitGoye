================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 22:13:30.033394
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.530

MAE (lower is better):
  Best: Gradient Boosting = 1.702

R² (higher is better):
  Best: Gradient Boosting = 0.909

MAPE (lower is better):
  Best: XGBoost = 4.631

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9093
   Test RMSE: 2.5299
   Test MAE: 1.7021
   Overfit Gap: -1.7222

2. XGBoost
   Test R²: 0.9049
   Test RMSE: 2.5907
   Test MAE: 1.7063
   Overfit Gap: -1.7476

3. LightGBM
   Test R²: 0.8929
   Test RMSE: 2.7491
   Test MAE: 1.8053
   Overfit Gap: -1.5325

4. Random Forest
   Test R²: 0.8860
   Test RMSE: 2.8364
   Test MAE: 1.8449
   Overfit Gap: -1.4414

5. Decision Tree
   Test R²: 0.7964
   Test RMSE: 3.7904
   Test MAE: 2.4949
   Overfit Gap: -1.9244

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.7904
    MAE: 2.4949
    MAPE: 6.70%
    R²: 0.7964
    Max Error: 19.2800
    Median Abs Error: 1.4484

  Cross-Validation:
    RMSE: 4.4913 ± nan
    R²: 0.6849 ± 0.0465

  Residual Analysis:
    Mean: -0.0107
    Std: 3.7904
    Skewness: 0.2805
    Kurtosis: 5.0174

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.3951
    MAE: 0.8979
    R²: 0.9699

  Test Performance:
    RMSE: 2.8364
    MAE: 1.8449
    MAPE: 4.93%
    R²: 0.8860
    Max Error: 14.0972
    Median Abs Error: 1.0305

  Cross-Validation:
    RMSE: 3.0886 ± nan
    R²: 0.8511 ± 0.0235

  Residual Analysis:
    Mean: 0.2041
    Std: 2.8291
    Skewness: 0.7043
    Kurtosis: 4.2740

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8077
    MAE: 0.6211
    R²: 0.9899

  Test Performance:
    RMSE: 2.5299
    MAE: 1.7021
    MAPE: 4.67%
    R²: 0.9093
    Max Error: 13.4472
    Median Abs Error: 1.0889

  Cross-Validation:
    RMSE: 2.9192 ± nan
    R²: 0.8663 ± 0.0283

  Residual Analysis:
    Mean: 0.1045
    Std: 2.5277
    Skewness: 0.3201
    Kurtosis: 4.7266

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8431
    MAE: 0.6336
    R²: 0.9890

  Test Performance:
    RMSE: 2.5907
    MAE: 1.7063
    MAPE: 4.63%
    R²: 0.9049
    Max Error: 13.6756
    Median Abs Error: 1.0318

  Cross-Validation:
    RMSE: 2.8641 ± nan
    R²: 0.8714 ± 0.0289

  Residual Analysis:
    Mean: 0.0948
    Std: 2.5889
    Skewness: 0.2550
    Kurtosis: 5.2727

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2166
    MAE: 0.8946
    R²: 0.9771

  Test Performance:
    RMSE: 2.7491
    MAE: 1.8053
    MAPE: 4.88%
    R²: 0.8929
    Max Error: 15.0765
    Median Abs Error: 1.1047

  Cross-Validation:
    RMSE: 3.0739 ± nan
    R²: 0.8517 ± 0.0277

  Residual Analysis:
    Mean: 0.2105
    Std: 2.7411
    Skewness: 0.5339
    Kurtosis: 5.6436

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial