================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-27 21:51:25.565167
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.523

MAE (lower is better):
  Best: Gradient Boosting = 1.688

R² (higher is better):
  Best: Gradient Boosting = 0.910

MAPE (lower is better):
  Best: Gradient Boosting = 4.602

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9098
   Test RMSE: 2.5229
   Test MAE: 1.6879
   Overfit Gap: -1.7274

2. XGBoost
   Test R²: 0.9002
   Test RMSE: 2.6542
   Test MAE: 1.7449
   Overfit Gap: -1.8123

3. LightGBM
   Test R²: 0.8980
   Test RMSE: 2.6834
   Test MAE: 1.7936
   Overfit Gap: -1.4668

4. Random Forest
   Test R²: 0.8887
   Test RMSE: 2.8025
   Test MAE: 1.8192
   Overfit Gap: -1.3985

5. Decision Tree
   Test R²: 0.7990
   Test RMSE: 3.7664
   Test MAE: 2.4741
   Overfit Gap: -1.8597

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.9066
    MAE: 1.2484
    R²: 0.9437

  Test Performance:
    RMSE: 3.7664
    MAE: 2.4741
    MAPE: 6.71%
    R²: 0.7990
    Max Error: 19.2800
    Median Abs Error: 1.3941

  Cross-Validation:
    RMSE: 4.5490 ± nan
    R²: 0.6758 ± 0.0447

  Residual Analysis:
    Mean: 0.0652
    Std: 3.7658
    Skewness: 0.2896
    Kurtosis: 4.8110

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.4040
    MAE: 0.8982
    R²: 0.9695

  Test Performance:
    RMSE: 2.8025
    MAE: 1.8192
    MAPE: 4.87%
    R²: 0.8887
    Max Error: 14.0569
    Median Abs Error: 1.0688

  Cross-Validation:
    RMSE: 3.0533 ± nan
    R²: 0.8545 ± 0.0203

  Residual Analysis:
    Mean: 0.1580
    Std: 2.7981
    Skewness: 0.7349
    Kurtosis: 4.4003

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7955
    MAE: 0.6137
    R²: 0.9902

  Test Performance:
    RMSE: 2.5229
    MAE: 1.6879
    MAPE: 4.60%
    R²: 0.9098
    Max Error: 12.8763
    Median Abs Error: 1.0592

  Cross-Validation:
    RMSE: 2.9168 ± nan
    R²: 0.8667 ± 0.0263

  Residual Analysis:
    Mean: 0.1477
    Std: 2.5186
    Skewness: 0.3642
    Kurtosis: 4.6579

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8419
    MAE: 0.6287
    R²: 0.9890

  Test Performance:
    RMSE: 2.6542
    MAE: 1.7449
    MAPE: 4.73%
    R²: 0.9002
    Max Error: 13.7753
    Median Abs Error: 1.1477

  Cross-Validation:
    RMSE: 2.8540 ± nan
    R²: 0.8723 ± 0.0267

  Residual Analysis:
    Mean: 0.1168
    Std: 2.6517
    Skewness: 0.0580
    Kurtosis: 5.0122

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2167
    MAE: 0.8954
    R²: 0.9771

  Test Performance:
    RMSE: 2.6834
    MAE: 1.7936
    MAPE: 4.86%
    R²: 0.8980
    Max Error: 13.8792
    Median Abs Error: 1.1648

  Cross-Validation:
    RMSE: 3.0488 ± nan
    R²: 0.8542 ± 0.0277

  Residual Analysis:
    Mean: 0.1801
    Std: 2.6774
    Skewness: 0.3832
    Kurtosis: 4.8805

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial