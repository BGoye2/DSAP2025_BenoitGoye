================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 18:23:40.611585
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.518

MAE (lower is better):
  Best: XGBoost = 1.673

R² (higher is better):
  Best: Gradient Boosting = 0.910

MAPE (lower is better):
  Best: XGBoost = 4.536

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9101
   Test RMSE: 2.5184
   Test MAE: 1.6900
   Overfit Gap: -1.7432

2. XGBoost
   Test R²: 0.9077
   Test RMSE: 2.5517
   Test MAE: 1.6727
   Overfit Gap: -1.7165

3. LightGBM
   Test R²: 0.8954
   Test RMSE: 2.7169
   Test MAE: 1.7856
   Overfit Gap: -1.4867

4. Random Forest
   Test R²: 0.8868
   Test RMSE: 2.8271
   Test MAE: 1.8204
   Overfit Gap: -1.4145

5. Decision Tree
   Test R²: 0.7952
   Test RMSE: 3.8022
   Test MAE: 2.4934
   Overfit Gap: -1.9363

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.8022
    MAE: 2.4934
    MAPE: 6.71%
    R²: 0.7952
    Max Error: 19.2800
    Median Abs Error: 1.4484

  Cross-Validation:
    RMSE: 4.5053 ± nan
    R²: 0.6825 ± 0.0483

  Residual Analysis:
    Mean: -0.0247
    Std: 3.8022
    Skewness: 0.1288
    Kurtosis: 5.0308

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.4125
    MAE: 0.9010
    R²: 0.9691

  Test Performance:
    RMSE: 2.8271
    MAE: 1.8204
    MAPE: 4.86%
    R²: 0.8868
    Max Error: 13.9659
    Median Abs Error: 1.0173

  Cross-Validation:
    RMSE: 3.0834 ± nan
    R²: 0.8518 ± 0.0206

  Residual Analysis:
    Mean: 0.1627
    Std: 2.8224
    Skewness: 0.7632
    Kurtosis: 4.7652

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7752
    MAE: 0.5989
    R²: 0.9907

  Test Performance:
    RMSE: 2.5184
    MAE: 1.6900
    MAPE: 4.60%
    R²: 0.9101
    Max Error: 13.4462
    Median Abs Error: 1.0107

  Cross-Validation:
    RMSE: 2.9186 ± nan
    R²: 0.8664 ± 0.0263

  Residual Analysis:
    Mean: 0.1510
    Std: 2.5139
    Skewness: 0.5563
    Kurtosis: 5.1785

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8352
    MAE: 0.6317
    R²: 0.9892

  Test Performance:
    RMSE: 2.5517
    MAE: 1.6727
    MAPE: 4.54%
    R²: 0.9077
    Max Error: 13.8384
    Median Abs Error: 1.0890

  Cross-Validation:
    RMSE: 2.8623 ± nan
    R²: 0.8716 ± 0.0260

  Residual Analysis:
    Mean: 0.1151
    Std: 2.5491
    Skewness: 0.3339
    Kurtosis: 5.3476

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2303
    MAE: 0.8986
    R²: 0.9766

  Test Performance:
    RMSE: 2.7169
    MAE: 1.7856
    MAPE: 4.83%
    R²: 0.8954
    Max Error: 14.6923
    Median Abs Error: 1.1398

  Cross-Validation:
    RMSE: 3.0480 ± nan
    R²: 0.8542 ± 0.0282

  Residual Analysis:
    Mean: 0.2243
    Std: 2.7077
    Skewness: 0.4967
    Kurtosis: 5.5305

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial