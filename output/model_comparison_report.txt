================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 21:22:08.400830
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.554

MAE (lower is better):
  Best: XGBoost = 1.699

R² (higher is better):
  Best: Gradient Boosting = 0.908

MAPE (lower is better):
  Best: XGBoost = 4.609

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9076
   Test RMSE: 2.5541
   Test MAE: 1.7185
   Overfit Gap: -1.7600

2. XGBoost
   Test R²: 0.9030
   Test RMSE: 2.6167
   Test MAE: 1.6988
   Overfit Gap: -1.7712

3. LightGBM
   Test R²: 0.8952
   Test RMSE: 2.7198
   Test MAE: 1.7979
   Overfit Gap: -1.4760

4. Random Forest
   Test R²: 0.8850
   Test RMSE: 2.8490
   Test MAE: 1.8530
   Overfit Gap: -1.4413

5. Decision Tree
   Test R²: 0.7905
   Test RMSE: 3.8457
   Test MAE: 2.5082
   Overfit Gap: -1.9797

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.8457
    MAE: 2.5082
    MAPE: 6.73%
    R²: 0.7905
    Max Error: 19.2800
    Median Abs Error: 1.4083

  Cross-Validation:
    RMSE: 4.4662 ± nan
    R²: 0.6878 ± 0.0523

  Residual Analysis:
    Mean: 0.0033
    Std: 3.8457
    Skewness: 0.1627
    Kurtosis: 4.8623

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.4078
    MAE: 0.8997
    R²: 0.9693

  Test Performance:
    RMSE: 2.8490
    MAE: 1.8530
    MAPE: 4.96%
    R²: 0.8850
    Max Error: 14.4196
    Median Abs Error: 1.0897

  Cross-Validation:
    RMSE: 3.0769 ± nan
    R²: 0.8522 ± 0.0212

  Residual Analysis:
    Mean: 0.1799
    Std: 2.8434
    Skewness: 0.7026
    Kurtosis: 4.4348

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7941
    MAE: 0.6111
    R²: 0.9902

  Test Performance:
    RMSE: 2.5541
    MAE: 1.7185
    MAPE: 4.68%
    R²: 0.9076
    Max Error: 13.7192
    Median Abs Error: 1.1087

  Cross-Validation:
    RMSE: 2.9048 ± nan
    R²: 0.8677 ± 0.0274

  Residual Analysis:
    Mean: 0.1310
    Std: 2.5508
    Skewness: 0.4750
    Kurtosis: 4.8469

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8454
    MAE: 0.6389
    R²: 0.9889

  Test Performance:
    RMSE: 2.6167
    MAE: 1.6988
    MAPE: 4.61%
    R²: 0.9030
    Max Error: 14.4013
    Median Abs Error: 1.0934

  Cross-Validation:
    RMSE: 2.9092 ± nan
    R²: 0.8672 ± 0.0301

  Residual Analysis:
    Mean: 0.1252
    Std: 2.6137
    Skewness: 0.2381
    Kurtosis: 5.9987

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2438
    MAE: 0.9155
    R²: 0.9760

  Test Performance:
    RMSE: 2.7198
    MAE: 1.7979
    MAPE: 4.89%
    R²: 0.8952
    Max Error: 14.7956
    Median Abs Error: 1.1660

  Cross-Validation:
    RMSE: 3.0586 ± nan
    R²: 0.8530 ± 0.0338

  Residual Analysis:
    Mean: 0.1807
    Std: 2.7138
    Skewness: 0.3712
    Kurtosis: 5.2836

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial