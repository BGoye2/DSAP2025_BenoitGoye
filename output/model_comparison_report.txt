================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 21:14:57.560940
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.585

MAE (lower is better):
  Best: Gradient Boosting = 1.722

R² (higher is better):
  Best: Gradient Boosting = 0.905

MAPE (lower is better):
  Best: Gradient Boosting = 4.689

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9053
   Test RMSE: 2.5855
   Test MAE: 1.7220
   Overfit Gap: -1.8000

2. XGBoost
   Test R²: 0.9037
   Test RMSE: 2.6069
   Test MAE: 1.7464
   Overfit Gap: -1.7881

3. LightGBM
   Test R²: 0.8952
   Test RMSE: 2.7193
   Test MAE: 1.7951
   Overfit Gap: -1.4762

4. Random Forest
   Test R²: 0.8900
   Test RMSE: 2.7863
   Test MAE: 1.8004
   Overfit Gap: -1.3970

5. Decision Tree
   Test R²: 0.7953
   Test RMSE: 3.8011
   Test MAE: 2.4928
   Overfit Gap: -1.9351

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.8011
    MAE: 2.4928
    MAPE: 6.72%
    R²: 0.7953
    Max Error: 19.2800
    Median Abs Error: 1.4484

  Cross-Validation:
    RMSE: 4.4982 ± nan
    R²: 0.6829 ± 0.0558

  Residual Analysis:
    Mean: -0.0366
    Std: 3.8009
    Skewness: 0.1375
    Kurtosis: 5.0480

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.3893
    MAE: 0.8901
    R²: 0.9701

  Test Performance:
    RMSE: 2.7863
    MAE: 1.8004
    MAPE: 4.82%
    R²: 0.8900
    Max Error: 13.9703
    Median Abs Error: 1.0586

  Cross-Validation:
    RMSE: 3.0722 ± nan
    R²: 0.8529 ± 0.0211

  Residual Analysis:
    Mean: 0.1753
    Std: 2.7808
    Skewness: 0.6036
    Kurtosis: 4.6244

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7855
    MAE: 0.6051
    R²: 0.9904

  Test Performance:
    RMSE: 2.5855
    MAE: 1.7220
    MAPE: 4.69%
    R²: 0.9053
    Max Error: 12.8712
    Median Abs Error: 1.1000

  Cross-Validation:
    RMSE: 2.9172 ± nan
    R²: 0.8665 ± 0.0272

  Residual Analysis:
    Mean: 0.1286
    Std: 2.5823
    Skewness: 0.2658
    Kurtosis: 4.6298

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8187
    MAE: 0.6192
    R²: 0.9896

  Test Performance:
    RMSE: 2.6069
    MAE: 1.7464
    MAPE: 4.73%
    R²: 0.9037
    Max Error: 12.5099
    Median Abs Error: 1.1205

  Cross-Validation:
    RMSE: 2.9253 ± nan
    R²: 0.8658 ± 0.0293

  Residual Analysis:
    Mean: 0.1195
    Std: 2.6041
    Skewness: 0.2012
    Kurtosis: 4.2528

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2432
    MAE: 0.9141
    R²: 0.9761

  Test Performance:
    RMSE: 2.7193
    MAE: 1.7951
    MAPE: 4.86%
    R²: 0.8952
    Max Error: 14.3823
    Median Abs Error: 1.1777

  Cross-Validation:
    RMSE: 3.0734 ± nan
    R²: 0.8516 ± 0.0321

  Residual Analysis:
    Mean: 0.1646
    Std: 2.7143
    Skewness: 0.4817
    Kurtosis: 5.0084

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial