================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 17:53:34.948595
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.542

MAE (lower is better):
  Best: Gradient Boosting = 1.695

R² (higher is better):
  Best: Gradient Boosting = 0.908

MAPE (lower is better):
  Best: Gradient Boosting = 4.630

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9084
   Test RMSE: 2.5423
   Test MAE: 1.6952
   Overfit Gap: -1.7505

2. XGBoost
   Test R²: 0.9080
   Test RMSE: 2.5482
   Test MAE: 1.7221
   Overfit Gap: -1.6919

3. LightGBM
   Test R²: 0.8929
   Test RMSE: 2.7495
   Test MAE: 1.8196
   Overfit Gap: -1.5274

4. Random Forest
   Test R²: 0.8873
   Test RMSE: 2.8201
   Test MAE: 1.8344
   Overfit Gap: -1.4226

5. Decision Tree
   Test R²: 0.8009
   Test RMSE: 3.7487
   Test MAE: 2.4646
   Overfit Gap: -1.8827

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.7487
    MAE: 2.4646
    MAPE: 6.63%
    R²: 0.8009
    Max Error: 19.2800
    Median Abs Error: 1.4400

  Cross-Validation:
    RMSE: 4.4788 ± nan
    R²: 0.6860 ± 0.0490

  Residual Analysis:
    Mean: -0.0516
    Std: 3.7483
    Skewness: 0.2424
    Kurtosis: 5.2117

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.3976
    MAE: 0.8955
    R²: 0.9697

  Test Performance:
    RMSE: 2.8201
    MAE: 1.8344
    MAPE: 4.91%
    R²: 0.8873
    Max Error: 14.0097
    Median Abs Error: 1.1184

  Cross-Validation:
    RMSE: 3.0776 ± nan
    R²: 0.8524 ± 0.0216

  Residual Analysis:
    Mean: 0.1791
    Std: 2.8144
    Skewness: 0.7471
    Kurtosis: 4.5982

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7918
    MAE: 0.6119
    R²: 0.9903

  Test Performance:
    RMSE: 2.5423
    MAE: 1.6952
    MAPE: 4.63%
    R²: 0.9084
    Max Error: 12.4919
    Median Abs Error: 1.0796

  Cross-Validation:
    RMSE: 2.9275 ± nan
    R²: 0.8657 ± 0.0268

  Residual Analysis:
    Mean: 0.1390
    Std: 2.5385
    Skewness: 0.3281
    Kurtosis: 4.7227

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8564
    MAE: 0.6435
    R²: 0.9886

  Test Performance:
    RMSE: 2.5482
    MAE: 1.7221
    MAPE: 4.69%
    R²: 0.9080
    Max Error: 13.2286
    Median Abs Error: 1.1485

  Cross-Validation:
    RMSE: 2.8529 ± nan
    R²: 0.8724 ± 0.0253

  Residual Analysis:
    Mean: 0.1070
    Std: 2.5460
    Skewness: 0.2457
    Kurtosis: 4.4569

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2221
    MAE: 0.8949
    R²: 0.9769

  Test Performance:
    RMSE: 2.7495
    MAE: 1.8196
    MAPE: 4.93%
    R²: 0.8929
    Max Error: 14.2538
    Median Abs Error: 1.1161

  Cross-Validation:
    RMSE: 3.0716 ± nan
    R²: 0.8519 ± 0.0296

  Residual Analysis:
    Mean: 0.1822
    Std: 2.7435
    Skewness: 0.3405
    Kurtosis: 4.6027

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial