================================================================================
COMPREHENSIVE MODEL COMPARISON REPORT
================================================================================

Generated: 2025-12-30 18:37:45.736740
Dataset: output/processed_data.csv
Number of models: 5
Test set size: 365

================================================================================
BEST MODELS BY METRIC
================================================================================

RMSE (lower is better):
  Best: Gradient Boosting = 2.554

MAE (lower is better):
  Best: Gradient Boosting = 1.719

R² (higher is better):
  Best: Gradient Boosting = 0.908

MAPE (lower is better):
  Best: Gradient Boosting = 4.685

================================================================================
OVERALL MODEL RANKING (by Test R²)
================================================================================

1. Gradient Boosting
   Test R²: 0.9076
   Test RMSE: 2.5544
   Test MAE: 1.7193
   Overfit Gap: -1.7615

2. XGBoost
   Test R²: 0.9034
   Test RMSE: 2.6115
   Test MAE: 1.7365
   Overfit Gap: -1.7682

3. LightGBM
   Test R²: 0.8980
   Test RMSE: 2.6832
   Test MAE: 1.7645
   Overfit Gap: -1.4613

4. Random Forest
   Test R²: 0.8871
   Test RMSE: 2.8234
   Test MAE: 1.8432
   Overfit Gap: -1.4258

5. Decision Tree
   Test R²: 0.7995
   Test RMSE: 3.7622
   Test MAE: 2.4643
   Overfit Gap: -1.8962

================================================================================
DETAILED MODEL STATISTICS
================================================================================

Decision Tree:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.8660
    MAE: 1.2507
    R²: 0.9461

  Test Performance:
    RMSE: 3.7622
    MAE: 2.4643
    MAPE: 6.64%
    R²: 0.7995
    Max Error: 19.2800
    Median Abs Error: 1.4200

  Cross-Validation:
    RMSE: 4.4997 ± nan
    R²: 0.6826 ± 0.0536

  Residual Analysis:
    Mean: -0.0610
    Std: 3.7617
    Skewness: 0.1994
    Kurtosis: 5.2206

Random Forest:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.3977
    MAE: 0.8949
    R²: 0.9697

  Test Performance:
    RMSE: 2.8234
    MAE: 1.8432
    MAPE: 4.94%
    R²: 0.8871
    Max Error: 14.1427
    Median Abs Error: 1.0885

  Cross-Validation:
    RMSE: 3.0852 ± nan
    R²: 0.8514 ± 0.0207

  Residual Analysis:
    Mean: 0.1970
    Std: 2.8166
    Skewness: 0.6121
    Kurtosis: 4.2199

Gradient Boosting:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.7929
    MAE: 0.6100
    R²: 0.9903

  Test Performance:
    RMSE: 2.5544
    MAE: 1.7193
    MAPE: 4.69%
    R²: 0.9076
    Max Error: 13.5169
    Median Abs Error: 1.1152

  Cross-Validation:
    RMSE: 2.9288 ± nan
    R²: 0.8655 ± 0.0261

  Residual Analysis:
    Mean: 0.1169
    Std: 2.5517
    Skewness: 0.3972
    Kurtosis: 4.7457

XGBoost:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 0.8433
    MAE: 0.6312
    R²: 0.9890

  Test Performance:
    RMSE: 2.6115
    MAE: 1.7365
    MAPE: 4.72%
    R²: 0.9034
    Max Error: 12.5163
    Median Abs Error: 1.0529

  Cross-Validation:
    RMSE: 2.8977 ± nan
    R²: 0.8686 ± 0.0235

  Residual Analysis:
    Mean: 0.0846
    Std: 2.6102
    Skewness: 0.1515
    Kurtosis: 4.5330

LightGBM:
--------------------------------------------------------------------------------
  Training Performance:
    RMSE: 1.2219
    MAE: 0.8985
    R²: 0.9769

  Test Performance:
    RMSE: 2.6832
    MAE: 1.7645
    MAPE: 4.80%
    R²: 0.8980
    Max Error: 14.8024
    Median Abs Error: 1.1616

  Cross-Validation:
    RMSE: 3.0674 ± nan
    R²: 0.8523 ± 0.0303

  Residual Analysis:
    Mean: 0.1998
    Std: 2.6758
    Skewness: 0.4748
    Kurtosis: 5.6252

================================================================================
RECOMMENDATIONS
================================================================================

✓ Best Overall Model: Gradient Boosting
  Recommended for: General predictions

✓ Best Interpretable Model: Decision Tree
  Recommended for: When interpretability is crucial